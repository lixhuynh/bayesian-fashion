{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Ex9nQQQpnAdV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = tfds.load(name='fashion_mnist',\n",
        "                                  split=['train', 'test'],\n",
        "                                  as_supervised=True)\n",
        "\n",
        "def ohe_normalize(images, labels):\n",
        "    images = tf.cast(images, tf.float32)\n",
        "    images = tf.divide(images, 255.0)\n",
        "    labels = tf.one_hot(labels, 10)\n",
        "    return images, labels\n",
        "\n",
        "train_data = train_data.batch(128).map(ohe_normalize).shuffle(128).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.batch(128).map(ohe_normalize).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "HOlWzo9gnkiz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 60000\n",
        "def divergence_fn(q, p, q_tensor):\n",
        "  return tf.reduce_mean(q.log_prob(q_tensor) - p.log_prob(q_tensor)) / train_size\n",
        "\n",
        "def createConvReparamLayer(filters, kernel_size, activation):\n",
        "  tfpl = tfp.layers\n",
        "  return tfpl.Convolution2DReparameterization(\n",
        "      filters=filters,\n",
        "      kernel_size=kernel_size,\n",
        "      activation=activation,\n",
        "      padding='same',\n",
        "      kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "      bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "      kernel_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "      bias_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "      kernel_divergence_fn=divergence_fn,\n",
        "      bias_divergence_fn=divergence_fn)\n",
        "\n",
        "def createDenseReparamLayer(unit_num):\n",
        "  tfpl = tfp.layers\n",
        "  return tfpl.DenseReparameterization(\n",
        "      units=tfp.layers.OneHotCategorical.params_size(unit_num),\n",
        "      activation=None,\n",
        "      kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "      bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
        "      kernel_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "      bias_prior_fn=tfpl.default_multivariate_normal_fn,\n",
        "      kernel_divergence_fn=divergence_fn,\n",
        "      bias_divergence_fn=divergence_fn)\n",
        "\n",
        "def createModel():\n",
        "  tfpl = tfp.layers\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.InputLayer((28, 28, 1)),\n",
        "      createConvReparamLayer(16, 3, 'swish'),\n",
        "      tf.keras.layers.MaxPooling2D(2),\n",
        "      createConvReparamLayer(32, 3, 'swish'),\n",
        "      tf.keras.layers.MaxPooling2D(2),\n",
        "      createConvReparamLayer(64, 3, 'swish'),\n",
        "      tf.keras.layers.GlobalMaxPooling2D(),\n",
        "      createDenseReparamLayer(10),\n",
        "      tfpl.OneHotCategorical(10)\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "7okesJ9voDT7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bcnn = createModel()\n",
        "bcnn.compile(loss=lambda y, y_hat: -y_hat.log_prob(y),\n",
        "             optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "             metrics=['accuracy'])\n",
        "bcnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNOTCx2HsNyS",
        "outputId": "2b5441a6-70c4-493b-a3d8-e89e08cce94f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_reparameterization_  (None, 28, 28, 16)        320       \n",
            " 27 (Conv2DReparameterizati                                      \n",
            " on)                                                             \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPooli  (None, 14, 14, 16)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_reparameterization_  (None, 14, 14, 32)        9280      \n",
            " 28 (Conv2DReparameterizati                                      \n",
            " on)                                                             \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 7, 7, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_reparameterization_  (None, 7, 7, 64)          36992     \n",
            " 29 (Conv2DReparameterizati                                      \n",
            " on)                                                             \n",
            "                                                                 \n",
            " global_max_pooling2d_10 (G  (None, 64)                0         \n",
            " lobalMaxPooling2D)                                              \n",
            "                                                                 \n",
            " dense_reparameterization_1  (None, 10)                1300      \n",
            " 1 (DenseReparameterization                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " one_hot_categorical_11 (On  ((None, 10),              0         \n",
            " eHotCategorical)             (None, 10))                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47892 (187.08 KB)\n",
            "Trainable params: 47892 (187.08 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bcnn.fit(train_data, epochs=12, validation_data=test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sygV8FDQsZMY",
        "outputId": "4708c2cb-5413-4899-85df-7c8f6d70b1d0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "469/469 [==============================] - 41s 79ms/step - loss: 2.2010 - accuracy: 0.4292 - val_loss: 1.7483 - val_accuracy: 0.6070\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 1.6414 - accuracy: 0.6591 - val_loss: 1.5891 - val_accuracy: 0.6808\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 1.5016 - accuracy: 0.7155 - val_loss: 1.4695 - val_accuracy: 0.7292\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 1.4151 - accuracy: 0.7450 - val_loss: 1.4022 - val_accuracy: 0.7617\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 34s 73ms/step - loss: 1.3445 - accuracy: 0.7720 - val_loss: 1.3602 - val_accuracy: 0.7680\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 35s 75ms/step - loss: 1.2945 - accuracy: 0.7884 - val_loss: 1.3101 - val_accuracy: 0.7809\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 1.2530 - accuracy: 0.7985 - val_loss: 1.2688 - val_accuracy: 0.7979\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 33s 71ms/step - loss: 1.2139 - accuracy: 0.8097 - val_loss: 1.2265 - val_accuracy: 0.8071\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 1.1783 - accuracy: 0.8149 - val_loss: 1.1960 - val_accuracy: 0.8155\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 33s 71ms/step - loss: 1.1510 - accuracy: 0.8216 - val_loss: 1.1744 - val_accuracy: 0.8122\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 36s 76ms/step - loss: 1.1229 - accuracy: 0.8278 - val_loss: 1.1342 - val_accuracy: 0.8150\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 35s 75ms/step - loss: 1.0980 - accuracy: 0.8302 - val_loss: 1.1233 - val_accuracy: 0.8251\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x793ed76a3490>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}